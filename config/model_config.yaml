# Actor-Critic Model Configuration
model:
  name: "ClashRoyaleActorCritic"
  
  # Input dimensions
  state_shape:
    field: [18, 32, 3]  # Game field grid with RGB channels
    elixir: 1           # Current elixir (normalized 0-1)
    hand: 8             # Cards in hand (one-hot)
    towers_hp: 6        # HP of all towers
    time_left: 1        # Remaining match time
    
  # Network architecture
  backbone:
    type: "ResNet18"
    pretrained: false
    freeze_layers: 0
    
  encoder:
    type: "LSTM"
    hidden_size: 256
    num_layers: 2
    dropout: 0.1
    
  actor:
    card_policy:
      hidden_layers: [512, 256]
      output_size: 9  # 8 cards + wait action
      activation: "relu"
      
    position_policy:
      hidden_layers: [512, 256]
      output_size: 2  # x, y coordinates
      activation: "tanh"
      
    timing_policy:
      hidden_layers: [256, 128]
      output_size: 1  # timing delay
      activation: "sigmoid"
      
  critic:
    hidden_layers: [512, 256, 128]
    output_size: 1
    activation: "relu"
    
# Training hyperparameters
training:
  algorithm: "PPO"
  
  ppo:
    clip_epsilon: 0.2
    value_loss_coef: 0.5
    entropy_coef: 0.01
    max_grad_norm: 0.5
    
  optimizer:
    type: "Adam"
    lr: 0.0003
    weight_decay: 1e-5
    
  scheduler:
    type: "StepLR"
    step_size: 10000
    gamma: 0.9
    
  episodes_per_update: 4
  epochs_per_update: 4
  
# Reward configuration
rewards:
  tower_damage_dealt: 100
  tower_damage_taken: -100
  elixir_efficiency: 10
  successful_defense: 20
  positive_trade: 15
  match_win: 500
  match_loss: -200
